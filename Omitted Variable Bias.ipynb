{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Omitted Variable Bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook displays the effect of Omitted Variable Bias. (https://en.wikipedia.org/wiki/Omitted-variable_bias)\n",
    "<br>\n",
    "Full model: $Y=\\alpha+\\beta_1 \\cdot X+\\beta_2 \\cdot Z + \\epsilon$ with $\\alpha=0.5, \\beta_1=2$.\n",
    "<br>\n",
    "Reduced model (omitting Z): $Y=\\alpha+\\beta_1 \\cdot X + \\epsilon$\n",
    "<br><br>\n",
    "Omitted Variable Bias occurs when \n",
    "<br>1) Z is correlated with X ($cov(Z, X) \\neq 0$) \n",
    "<br>2) Z has a non-zero coefficient ($\\beta_2 \\neq 0$).\n",
    "<br><br>\n",
    "Run the code chunk below, adjust the slidebars and press \"Run Interact\" to create the visualizations. \n",
    "<br>Make sure the two parameters, beta2 and cov, are set to nonzero to see the effect of the bias.\n",
    "<br>You can adjust the 'angle' and 'height' parameter to rotate & change the height of the 3d plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fa1525ecdf74d40b66be4731aa33d23"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.OVB>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math \n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import scipy.stats as stats\n",
    "from sklearn import datasets, linear_model\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import matplotlib.animation as anim\n",
    "\n",
    "def OVB(beta2, cov, angle=280, height=30):\n",
    "    A = beta2\n",
    "    alpha = 0.5\n",
    "    beta1 = 2.0\n",
    "    N = 500\n",
    "    mean = [0, 0]\n",
    "    cov = [[1, cov], [cov, 1]]\n",
    "    np.random.seed(123)\n",
    "    sampleX, sampleZ = np.random.multivariate_normal(mean, cov, N).T\n",
    "    \n",
    "    #sampleY = np.array([alpha + x * beta1 + z * beta2 -4 + np.random.rand(1)*8 for x, z in zip(sampleX, sampleZ)])\n",
    "    sampleY = np.array([alpha + x * beta1 + z * beta2 + np.random.normal(0, 1)*4 for x, z in zip(sampleX, sampleZ)])\n",
    "\n",
    "    fullregr = linear_model.LinearRegression()\n",
    "    fullregr.fit(np.transpose(np.vstack((sampleX, sampleZ))), sampleY.reshape(N, 1))   \n",
    "    \n",
    "    smallregr = linear_model.LinearRegression()\n",
    "    smallregr.fit(sampleX.reshape(N, 1), sampleY.reshape(N, 1))     \n",
    "    \n",
    "    fullxx = np.linspace(-3, 3, 300)\n",
    "    fullzz = np.linspace(-3, 3, 300)\n",
    "    #fullyy = [fullregr.intercept_ + x * fullregr.coef_[0][0] + z * fullregr.coef_[0][1] for x,z in zip(fullxx, fullzz)]\n",
    "    fullyy = [fullregr.intercept_ + x * fullregr.coef_[0][0] for x in fullxx]\n",
    "\n",
    "    smallxx = np.linspace(-3, 3, 300)\n",
    "    smallzz = np.linspace(-3, 3, 300)\n",
    "    smallyy = [smallregr.intercept_ + x * smallregr.coef_[0][0] for x in smallxx]        \n",
    "    \n",
    "\n",
    "    fig = plt.figure(figsize=(20, 7))    \n",
    "    \n",
    "    ax1 = fig.add_subplot(1, 2, 1, projection='3d')\n",
    "    ax2 = fig.add_subplot(1, 2, 2)\n",
    "    ax1.plot3D(fullxx, fullzz, zs=np.array(fullyy).flatten(), c='r', label=\"full model\")\n",
    "    ax1.scatter3D(sampleX, sampleZ, sampleY, label=\"sample points\")\n",
    "    ax1.view_init(height, azim=angle)\n",
    "    ax1.set_xlabel(\"X\")\n",
    "    ax1.set_ylabel(\"Z\")\n",
    "    ax1.set_zlabel(\"Y\")\n",
    "    ax1.set_title(\"3D plot of the full model\")\n",
    "    ax1.legend()    \n",
    "    \n",
    "    ax2.set_xlabel(\"X\")\n",
    "    ax2.set_ylabel(\"Y\")\n",
    "    ax2.plot(fullxx, fullyy, 'r', label=\"full model\")\n",
    "    ax2.scatter(sampleX, sampleY)\n",
    "    ax2.set_title(\"2D plot (Y~X) of the full model\")\n",
    "    ax2.legend()\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "    fig = plt.figure(figsize=(20, 7))\n",
    "    \n",
    "    ax1 = fig.add_subplot(1, 2, 1, projection='3d')\n",
    "    ax2 = fig.add_subplot(1, 2, 2)\n",
    "\n",
    "    ax1.view_init(height, azim=angle)\n",
    "    ax1.plot3D(smallxx, smallzz, zs=np.array(smallyy).flatten(), c='gray', label=\"reduced model\")\n",
    "    ax1.plot3D(fullxx, fullzz, zs=np.array(fullyy).flatten(), c='r', label=\"full model\")\n",
    "    ax1.scatter3D(sampleX, sampleZ, sampleY, label=\"sample points\")\n",
    "\n",
    "    ax1.set_xlabel(\"X\")\n",
    "    ax1.set_ylabel(\"Z\")\n",
    "    ax1.set_zlabel(\"Y\")\n",
    "    ax1.set_title(\"3D plot of the reduced model\")\n",
    "    ax1.legend()\n",
    "\n",
    "    ax2.set_xlabel(\"X\")\n",
    "    ax2.set_ylabel(\"Y\")\n",
    "    ax2.plot(smallxx, smallyy, 'gray', label=\"reduced model\")\n",
    "    ax2.plot(fullxx, fullyy, 'r', label=\"full model\")\n",
    "    ax2.scatter(sampleX, sampleY)\n",
    "    ax2.set_title(\"2D plot (Y~X) of the reduced model\")\n",
    "    ax2.legend()    \n",
    "    plt.show()\n",
    "\n",
    "    print (\"\\nTrue beta1 of the full model : 2\")\n",
    "    print (\"beta1hat from the full model : \"+str(fullregr.coef_[0][0]))\n",
    "    print (\"beta1hat from the reduced model, with Z omitted (N=500, graphed above): \" + str(smallregr.coef_[0][0]))\n",
    "    \n",
    "    N=5000\n",
    "    sampleX, sampleZ = np.random.multivariate_normal(mean, cov, N).T\n",
    "    sampleY = np.array([alpha + x * beta1 + z * beta2 + np.random.normal(0, 1)*4 for x, z in zip(sampleX, sampleZ)])  \n",
    "    smallregr = linear_model.LinearRegression()\n",
    "    smallregr.fit(sampleX.reshape(N, 1), sampleY.reshape(N, 1))  \n",
    "    print (\"beta1hat from the reduced model, with Z omitted (N=5000, not graphed): \" + str(smallregr.coef_[0][0]))\n",
    "    print (\"-> Thus, the bias is maintained even with very large Ns\")\n",
    "    \n",
    "\n",
    "interact_manual(OVB, beta2=(-5, 5), cov=(-0.9, 0.9), angle=(0, 360), height=(0, 40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
